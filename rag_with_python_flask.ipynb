{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPehg9CYFcNs5t2wwKG1U4A",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ali-siddiquii/Multi-Document-Query-Assistant-with-OpenAI-and-ChromaDB/blob/main/rag_with_python_flask.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "To run this project, create a .env file in the project root directory with the following variables:\n",
        "\n",
        "---------------------------------------------\n",
        "API_KEY=your_api_key_here\n",
        "NGROK_AUTH_TOKEN=your_ngrok_auth_token_here\n",
        "---------------------------------------------\n",
        "\n",
        "\n",
        "\n",
        "The .env file will be loaded automatically\n",
        "\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "cd6SelJZppzB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "7LqbSBSMlqJG"
      },
      "outputs": [],
      "source": [
        "\n",
        "%pip install llama-index-agent-openai\n",
        "%pip install llama-index-embeddings-openai\n",
        "%pip install llama-index-llms-openai\n",
        "%pip install chromadb\n",
        "%pip install docx2txt\n",
        "%pip install python-dotenv\n",
        "\n",
        "%pip install flask\n",
        "%pip install flask-ngrok\n",
        "\n",
        "%pip install pyngrok\n",
        "\n",
        "\n",
        "%pip install llama-index\n",
        "%pip install python-docx\n",
        "%pip install pdfminer.six\n",
        "\n",
        "from flask import Flask, request, jsonify\n",
        "from flask_ngrok import run_with_ngrok\n",
        "from pyngrok import ngrok\n",
        "\n",
        "\n",
        "\n",
        "from llama_index.core import (\n",
        "    VectorStoreIndex,\n",
        "    SimpleKeywordTableIndex,\n",
        "    SimpleDirectoryReader,\n",
        ")\n",
        "\n",
        "!pip install pyngrok\n",
        "!pip install flask\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from flask import Flask, jsonify, make_response, request\n",
        "from flask_ngrok import run_with_ngrok\n",
        "\n",
        "\n",
        "\n",
        "import os\n",
        "import threading\n",
        "\n",
        "from flask import Flask\n",
        "from pyngrok import ngrok\n",
        "\n",
        "from flask import Flask, request, jsonify\n",
        "from llama_index.core import SummaryIndex\n",
        "from llama_index.core.schema import IndexNode\n",
        "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
        "from llama_index.llms.openai import OpenAI\n",
        "from llama_index.core.callbacks import CallbackManager\n",
        "\n",
        "from llama_index.agent.openai import OpenAIAgent\n",
        "from llama_index.core import load_index_from_storage, StorageContext\n",
        "from llama_index.core.node_parser import SentenceSplitter\n",
        "import os\n",
        "\n",
        "from llama_index.llms.openai import OpenAI\n",
        "from llama_index.embeddings.openai import OpenAIEmbedding\n",
        "from llama_index.core import Settings\n",
        "import openai\n",
        "\n",
        "import chromadb\n",
        "chroma_client = chromadb.Client()\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "from pathlib import Path\n",
        "from werkzeug.utils import secure_filename\n",
        "from docx import Document\n",
        "import os\n",
        "from pdfminer.high_level import extract_text\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "OPEN_API_KEY = os.getenv('API_KEY')\n",
        "openai.api_key = os.getenv('API_KEY')\n",
        "#openai.api_key = os.environ[\"API_KEY\"]\n",
        "Settings.llm = OpenAI(temperature=0, model=\"gpt-3.5-turbo\")\n",
        "Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-ada-002\")\n",
        "\n",
        "\n",
        "ngrok_auth_token = os.getenv('NGROK_AUTH_TOKEN')\n",
        "!ngrok config add-authtoken $ngrok_auth_token\n",
        "\n",
        "\n",
        "app = Flask(__name__)\n",
        "run_with_ngrok(app)\n",
        "\n",
        "node_parser = SentenceSplitter()\n",
        "uploaded_docs = []\n",
        "\n",
        "\n",
        "try:\n",
        "    collection = chroma_client.create_collection(name=\"my_collection\")\n",
        "except:\n",
        "    collection = chroma_client.get_collection(name=\"my_collection\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "app = Flask(__name__)\n",
        "run_with_ngrok(app)  # Start ngrok when app is run\n",
        "\n",
        "top_agent = None\n",
        "# Configure upload folder\n",
        "UPLOAD_FOLDER = '/content/uploads'\n",
        "app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER\n",
        "\n",
        "# Ensure the upload folder exists\n",
        "if not os.path.exists(UPLOAD_FOLDER):\n",
        "    os.makedirs(UPLOAD_FOLDER)\n",
        "\n",
        "agents = {}\n",
        "query_engines = {}\n",
        "all_nodes = []\n",
        "\n",
        "node_parser = SentenceSplitter()\n",
        "\n",
        "\n",
        "# Function to build agent tools\n",
        "def build_agent_tools(city_docs):\n",
        "    \"\"\"Creates query agents and tools for document interaction.\"\"\"\n",
        "    global top_agent\n",
        "    for wiki_title, doc_nodes in city_docs.items():\n",
        "        # Split nodes from each document\n",
        "        nodes = SentenceSplitter().get_nodes_from_documents(doc_nodes)\n",
        "\n",
        "        # Create indices and query engines\n",
        "        summary_index = SummaryIndex(nodes)\n",
        "        vector_index = VectorStoreIndex(nodes)\n",
        "        vector_query_engine = vector_index.as_query_engine(llm=Settings.llm)\n",
        "        summary_query_engine = summary_index.as_query_engine(llm=Settings.llm)\n",
        "\n",
        "        # Define tools for each document\n",
        "        query_engine_tools = [\n",
        "            QueryEngineTool(\n",
        "                query_engine=vector_query_engine,\n",
        "                metadata=ToolMetadata(name=\"vector_tool\", description=f\"Useful for specific queries about {wiki_title}.\")\n",
        "            ),\n",
        "            QueryEngineTool(\n",
        "                query_engine=summary_query_engine,\n",
        "                metadata=ToolMetadata(name=\"summary_tool\", description=f\"Provides a holistic summary of {wiki_title}.\")\n",
        "            )\n",
        "        ]\n",
        "\n",
        "        # Build agent with the tools\n",
        "        function_llm = OpenAI(model=\"gpt-4\")\n",
        "        agent = OpenAIAgent.from_tools(\n",
        "            query_engine_tools,\n",
        "            llm=function_llm,\n",
        "            verbose=True,\n",
        "            system_prompt=f\"Answer queries about {wiki_title}. Use tools provided; do not rely on prior knowledge.\"\n",
        "        )\n",
        "\n",
        "        base_index = VectorStoreIndex(all_nodes)\n",
        "        base_query_engine = base_index.as_query_engine(similarity_top_k=4)\n",
        "\n",
        "        agent = OpenAIAgent.from_tools(\n",
        "        query_engine_tools,\n",
        "        llm=function_llm,\n",
        "        verbose=True,\n",
        "        system_prompt=\n",
        "          f\"\"\"\\\n",
        "          You are a specialized agent designed to answer queries about {wiki_title}.\n",
        "          You must ALWAYS use at least one of the tools provided when answering a question; do NOT rely on prior knowledge.\\\n",
        "          \"\"\",\n",
        "              )\n",
        "\n",
        "        top_agent = agent\n",
        "\n",
        "        # Store agents and query engines for each document\n",
        "        agents[wiki_title] = agent\n",
        "        query_engines[wiki_title] = vector_index.as_query_engine(similarity_top_k=2)\n",
        "\n",
        "\n",
        "# Flask route for document upload\n",
        "@app.route('/upload', methods=['POST'])\n",
        "def upload_document():\n",
        "    try:\n",
        "        if 'files' not in request.files:\n",
        "            return jsonify({\"error\": \"No files part in the request.\"}), 400\n",
        "\n",
        "        files = request.files.getlist('files')\n",
        "        if not files:\n",
        "            return jsonify({\"error\": \"No files uploaded.\"}), 400\n",
        "\n",
        "\n",
        "        for file in files:\n",
        "            filename = secure_filename(file.filename)\n",
        "            file_path = os.path.join(app.config['UPLOAD_FOLDER'], filename)\n",
        "            file.save(file_path)  # Save each file to the upload directory\n",
        "\n",
        "        # Step 2: Define wiki_titles based on uploaded files\n",
        "        wiki_titles = [secure_filename(file.filename).split('.')[0] for file in files]  # Extract titles from filenames\n",
        "\n",
        "        # Step 3: Load documents using SimpleDirectoryReader\n",
        "        city_docs = {}\n",
        "        for wiki_title in wiki_titles:\n",
        "            # Load data using SimpleDirectoryReader for each file\n",
        "            city_docs[wiki_title] = SimpleDirectoryReader(input_files=[file_path]).load_data()\n",
        "\n",
        "        # Step 4: Initialize collections for agents and nodes\n",
        "        agents = {}\n",
        "        query_engines = {}\n",
        "        all_nodes = []\n",
        "\n",
        "        # Step 5: Process nodes and upsert embeddings\n",
        "        for idx, wiki_title in enumerate(wiki_titles):\n",
        "            nodes = node_parser.get_nodes_from_documents(city_docs[wiki_title])  # Parse nodes from documents\n",
        "            all_nodes.extend(nodes)\n",
        "\n",
        "            # Prepare unique IDs for each document\n",
        "            ids = [f\"{wiki_title}_{i}\" for i in range(len(nodes))]\n",
        "\n",
        "            # Upsert each node's text and ID into ChromaDB\n",
        "            for i, node in enumerate(nodes):\n",
        "                collection.upsert(\n",
        "                    documents=[node.text],  # Ensure node.text contains the document text\n",
        "                    ids=[ids[i]]  # Use unique ID for each document\n",
        "                )\n",
        "\n",
        "\n",
        "        build_agent_tools(city_docs)\n",
        "        return '''\n",
        "          <!DOCTYPE html>\n",
        "          <html lang=\"en\">\n",
        "          <head>\n",
        "              <meta charset=\"UTF-8\">\n",
        "              <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
        "              <title>Query Interface</title>\n",
        "          </head>\n",
        "          <body>\n",
        "              <h1>Query Interface</h1>\n",
        "              <p>Upload successful! Please enter your query below.</p>\n",
        "              <form action=\"/query\" method=\"POST\">\n",
        "                  <label for=\"query\">Enter your query:</label>\n",
        "                  <input type=\"text\" id=\"query\" name=\"query\" required>\n",
        "                  <button type=\"submit\">Submit Query</button>\n",
        "              </form>\n",
        "          </body>\n",
        "          </html>\n",
        "          '''\n",
        "\n",
        "    except Exception as e:\n",
        "        return jsonify({\"error\": \"An error occurred in /upload.\"}), 500\n",
        "\n",
        "\n",
        "\n",
        "# Flask route for querying the system\n",
        "@app.route('/query', methods=['POST'])\n",
        "def query_system():\n",
        "\n",
        "\n",
        "    user_query = request.form.get('query')\n",
        "    print(user_query)\n",
        "    if not user_query:\n",
        "        return jsonify({\"error\": \"No query provided.\"}), 400\n",
        "\n",
        "\n",
        "\n",
        "    response = top_agent.query(user_query)\n",
        "    print(response)\n",
        "\n",
        "    return f'''\n",
        "      <!DOCTYPE html>\n",
        "      <html lang=\"en\">\n",
        "      <head>\n",
        "          <meta charset=\"UTF-8\">\n",
        "          <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
        "          <title>Query Result</title>\n",
        "      </head>\n",
        "      <body>\n",
        "          <h1>Query Result</h1>\n",
        "          <p>Query submitted: {user_query}</p>\n",
        "          <h2>Response:</h2>\n",
        "          <p>{response}</p>\n",
        "          <a href=\"/upload\">Upload another document</a>  <!-- Link to go back to upload -->\n",
        "      </body>\n",
        "      </html>\n",
        "      '''\n",
        "\n",
        "# Flask route for updating a document (PUT)\n",
        "@app.route('/update_document/<doc_id>', methods=['PUT'])\n",
        "def update_document(doc_id):\n",
        "    new_content = request.json.get('content')\n",
        "    if not new_content:\n",
        "        return jsonify({\"error\": \"No new content provided.\"}), 400\n",
        "\n",
        "    # Delete old embedding, upsert new one\n",
        "    collection.upsert(documents=[new_content], ids=[doc_id])\n",
        "    return jsonify({\"status\": f\"Document {doc_id} updated.\"}), 200\n",
        "\n",
        "# Flask route for deleting a document (DELETE)\n",
        "@app.route('/delete_document/<doc_id>', methods=['DELETE'])\n",
        "def delete_document(doc_id):\n",
        "    collection.delete(ids=[doc_id])\n",
        "    return jsonify({\"status\": f\"Document {doc_id} deleted.\"}), 200\n",
        "\n",
        "# Flask route for server status check\n",
        "@app.route('/status', methods=['GET'])\n",
        "def status():\n",
        "    return jsonify({\"status\": \"Server is running\"}), 200\n",
        "\n"
      ],
      "metadata": {
        "id": "ezhnfj2kmNjY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "@app.route(\"/\", methods=['GET'])\n",
        "def homepage():\n",
        "\n",
        "    return '''\n",
        "    <!doctype html>\n",
        "    <title>Document Upload and Query System</title>\n",
        "    <h1>Upload Your Documents</h1>\n",
        "    <form method=\"post\" action=\"/upload\" enctype=\"multipart/form-data\">\n",
        "      <input type=\"file\" name=\"files\" multiple>\n",
        "      <input type=\"submit\" value=\"Upload\">\n",
        "    </form>\n",
        "\n",
        "\n",
        "    '''\n",
        "\n",
        "\n",
        "# Run the Flask app\n",
        "\n",
        "\n",
        "public_url=ngrok.connect(5000)\n",
        "print('* ngrok tunnel \"{}\" -> \"http://127.0.0.1:{}\"'.format(public_url, 5000))\n",
        "app.run()"
      ],
      "metadata": {
        "id": "hZK6TjfLm8z6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pkill ngrok\n",
        "# Disconnect all open tunnels\n",
        "for tunnel in ngrok.get_tunnels():\n",
        "    ngrok.disconnect(tunnel.public_url)\n",
        "\n",
        "# Kill any remaining ngrok processes\n",
        "import os\n",
        "os.system(\"pkill ngrok\")\n",
        "\n",
        "print(\"All ngrok tunnels have been reset.\")\n"
      ],
      "metadata": {
        "id": "aPFCxyOFmczY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jFdDCV6XobFH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}